import pandas as pd
import numpy as np
import joblib
import time
from collections import Counter
from underthesea import word_tokenize

# Load d·ªØ li·ªáu g·ªëc
train_data = pd.read_csv('data/train_data.csv')
test_data = pd.read_csv('data/test_data.csv')

# T·∫°o l·∫°i c·ªôt Processed_Question ƒë·ªÉ demo
def preprocess_text(text):
    tokens = word_tokenize(text.lower())
    # Remove stopwords (simple list)
    stopwords = ['t√¥i', 'ƒëang', 'l√†', 'c√≥', 'kh√¥ng', 'v√†', 'ho·∫∑c', 'nh∆∞ng', 'n·∫øu', 'th√¨']
    tokens = [word for word in tokens if word not in stopwords and word.isalpha()]
    return ' '.join(tokens)

# Apply preprocessing
train_data['Processed_Question'] = train_data['Question'].apply(preprocess_text)

# Load d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω
X_train_ml = np.load('data/X_train.npy')
X_test_ml = np.load('data/X_test.npy')
y_train = np.load('data/y_train.npy')
y_test = np.load('data/y_test.npy')

# Load deep learning data
X_train_dl = np.load('data/X_train_dl.npy')
X_test_dl = np.load('data/X_test_dl.npy')

# Load tokenizer v√† metadata
tokenizer = joblib.load('data/tokenizer.joblib')
label_encoder = joblib.load('data/label_encoder.joblib')
dl_metadata = joblib.load('data/dl_metadata.joblib')

# T·∫°o HTML report
html_content = """
<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ViMedical - B∆∞·ªõc 2: Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        .container {
            background: white;
            border-radius: 10px;
            padding: 30px;
            margin: 20px 0;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        h1, h2 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
        }
        .metric-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .metric-card {
            background: #f8f9fa;
            border: 2px solid #e9ecef;
            border-radius: 8px;
            padding: 20px;
            text-align: center;
            transition: transform 0.2s;
        }
        .metric-card:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
        }
        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #3498db;
        }
        .metric-label {
            color: #6c757d;
            margin-top: 5px;
        }
        .highlight {
            background: #e8f4fd;
            border-left: 4px solid #3498db;
            padding: 15px;
            margin: 20px 0;
            border-radius: 0 5px 5px 0;
        }
        .code {
            background: #f8f9fa;
            border: 1px solid #e9ecef;
            border-radius: 5px;
            padding: 15px;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            overflow-x: auto;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background-color: #f8f9fa;
            font-weight: bold;
        }
        tr:nth-child(even) {
            background-color: #f8f9fa;
        }
        .footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 5px;
            color: #6c757d;
        }
        .success {
            color: #28a745;
            font-weight: bold;
        }
        .info {
            color: #17a2b8;
        }
        .warning {
            color: #ffc107;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ü©∫ ViMedical - H·ªá Chuy√™n Gia B·ªánh T·∫≠t</h1>
        <h2>üìä B∆∞·ªõc 2: Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu</h2>

        <div class="highlight">
            <strong>üéØ M·ª•c ti√™u:</strong> Chu·∫©n b·ªã v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu vƒÉn b·∫£n ti·∫øng Vi·ªát cho c√°c m√¥ h√¨nh h·ªçc m√°y v√† h·ªçc s√¢u
        </div>

        <h2>üìà T·ªïng Quan D·ªØ Li·ªáu</h2>
        <div class="metric-grid">
"""

# Th√™m metrics cho d·ªØ li·ªáu g·ªëc
html_content += f"""
            <div class="metric-card">
                <div class="metric-value">{len(train_data)}</div>
                <div class="metric-label">M·∫´u Training</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{len(test_data)}</div>
                <div class="metric-label">M·∫´u Test</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{len(np.unique(y_train))}</div>
                <div class="metric-label">S·ªë L·ªõp B·ªánh T·∫≠t</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{len(train_data['Question'].str.split().sum())/len(train_data):.1f}</div>
                <div class="metric-label">T·ª´ Trung B√¨nh/C√¢u</div>
            </div>
"""

html_content += """
        </div>

        <h2>üî§ Ph√¢n T√≠ch VƒÉn B·∫£n G·ªëc</h2>
        <table>
            <thead>
                <tr>
                    <th>Th·ªëng K√™</th>
                    <th>Gi√° Tr·ªã</th>
                </tr>
            </thead>
            <tbody>
"""

# Ph√¢n t√≠ch vƒÉn b·∫£n
questions = train_data['Question']
word_counts = questions.str.split().str.len()
char_counts = questions.str.len()

html_content += f"""
                <tr>
                    <td>T·ªïng s·ªë c√¢u h·ªèi</td>
                    <td>{len(questions)}</td>
                </tr>
                <tr>
                    <td>S·ªë t·ª´ trung b√¨nh/c√¢u</td>
                    <td>{word_counts.mean():.1f}</td>
                </tr>
                <tr>
                    <td>S·ªë t·ª´ t·ªëi ƒëa/c√¢u</td>
                    <td>{word_counts.max()}</td>
                </tr>
                <tr>
                    <td>S·ªë t·ª´ t·ªëi thi·ªÉu/c√¢u</td>
                    <td>{word_counts.min()}</td>
                </tr>
                <tr>
                    <td>S·ªë k√Ω t·ª± trung b√¨nh/c√¢u</td>
                    <td>{char_counts.mean():.1f}</td>
                </tr>
"""

html_content += """
            </tbody>
        </table>

        <h2>üßπ Ti·ªÅn X·ª≠ L√Ω VƒÉn B·∫£n</h2>
        <div class="highlight">
            <strong>C√°c b∆∞·ªõc x·ª≠ l√Ω:</strong>
            <ul>
                <li>Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng</li>
                <li>Tokenization b·∫±ng Underthesea</li>
                <li>Lo·∫°i b·ªè stopwords c∆° b·∫£n</li>
                <li>Gi·ªØ l·∫°i ch·ªâ t·ª´ alphabetic</li>
            </ul>
        </div>

        <h3>üìù V√≠ D·ª• VƒÉn B·∫£n ƒê√£ X·ª≠ L√Ω</h3>
        <table>
            <thead>
                <tr>
                    <th>VƒÉn B·∫£n G·ªëc</th>
                    <th>VƒÉn B·∫£n ƒê√£ X·ª≠ L√Ω</th>
                </tr>
            </thead>
            <tbody>
"""

# Hi·ªÉn th·ªã 5 v√≠ d·ª• ƒë·∫ßu ti√™n
for i in range(min(5, len(train_data))):
    original = train_data['Question'].iloc[i][:100] + "..." if len(train_data['Question'].iloc[i]) > 100 else train_data['Question'].iloc[i]
    processed = train_data['Processed_Question'].iloc[i][:100] + "..." if len(str(train_data['Processed_Question'].iloc[i])) > 100 else str(train_data['Processed_Question'].iloc[i])
    html_content += f"""
                <tr>
                    <td>{original}</td>
                    <td>{processed}</td>
                </tr>
"""

html_content += """
            </tbody>
        </table>

        <h2>ü§ñ Chu·∫©n B·ªã D·ªØ Li·ªáu Cho C√°c M√¥ H√¨nh</h2>

        <h3>üìä D·ªØ Li·ªáu Cho M√¥ H√¨nh H·ªçc M√°y Truy·ªÅn Th·ªëng</h3>
        <div class="metric-grid">
"""

html_content += f"""
            <div class="metric-card">
                <div class="metric-value">{X_train_ml.shape[1]}</div>
                <div class="metric-label">K√≠ch Th∆∞·ªõc T·ª´ V·ª±ng</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{X_train_ml.shape[0]}</div>
                <div class="metric-label">S·ªë M·∫´u Training</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{X_train_ml.shape[1]}</div>
                <div class="metric-label">S·ªë T√≠nh NƒÉng</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{np.sum(X_train_ml) / X_train_ml.size:.3f}</div>
                <div class="metric-label">T·ª∑ L·ªá Sparsity</div>
            </div>
"""

html_content += """
        </div>

        <h3>üß† D·ªØ Li·ªáu Cho M√¥ H√¨nh H·ªçc S√¢u</h3>
        <div class="metric-grid">
"""

vocab_size = dl_metadata['vocab_size']
max_seq_len = dl_metadata['max_sequence_length']

html_content += f"""
            <div class="metric-card">
                <div class="metric-value">{vocab_size}</div>
                <div class="metric-label">K√≠ch Th∆∞·ªõc T·ª´ V·ª±ng</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{X_train_dl.shape[0]}</div>
                <div class="metric-label">S·ªë M·∫´u Training</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{max_seq_len}</div>
                <div class="metric-label">ƒê·ªô D√†i Sequence T·ªëi ƒêa</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{len(tokenizer.word_index)}</div>
                <div class="metric-label">T·ªïng S·ªë T·ª´ Duy Nh·∫•t</div>
            </div>
"""

html_content += """
        </div>

        <h3>üî¢ V√≠ D·ª• Tokenization</h3>
        <div class="code">
"""

# Hi·ªÉn th·ªã v√≠ d·ª• tokenization
sample_text = train_data['Processed_Question'].iloc[0]
sample_sequence = X_train_dl[0][:20]  # Ch·ªâ hi·ªÉn th·ªã 20 token ƒë·∫ßu

html_content += f"""
<strong>VƒÉn b·∫£n g·ªëc:</strong> {sample_text}<br><br>
<strong>Sequence (20 token ƒë·∫ßu):</strong> {sample_sequence.tolist()}<br><br>
<strong>Mapping m·ªôt s·ªë token:</strong><br>
"""

# Hi·ªÉn th·ªã mapping cho m·ªôt s·ªë token ph·ªï bi·∫øn
word_index = tokenizer.word_index
for word, idx in list(word_index.items())[:10]:
    html_content += f"{word} ‚Üí {idx}<br>"

html_content += """
        </div>

        <h2>üè∑Ô∏è Ph√¢n T√≠ch Nh√£n (Labels)</h2>
        <div class="metric-grid">
"""

html_content += f"""
            <div class="metric-card">
                <div class="metric-value">{len(label_encoder.classes_)}</div>
                <div class="metric-label">T·ªïng S·ªë L·ªõp B·ªánh</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{max(Counter(y_train).values())}</div>
                <div class="metric-label">L·ªõp C√≥ Nhi·ªÅu M·∫´u Nh·∫•t</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{min(Counter(y_train).values())}</div>
                <div class="metric-label">L·ªõp C√≥ √çt M·∫´u Nh·∫•t</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{Counter(y_train).most_common(1)[0][0]}</div>
                <div class="metric-label">ID L·ªõp Ph·ªï Bi·∫øn Nh·∫•t</div>
            </div>
"""

html_content += """
        </div>

        <h3>üìã Top 10 L·ªõp B·ªánh Ph·ªï Bi·∫øn Nh·∫•t</h3>
        <table>
            <thead>
                <tr>
                    <th>T√™n B·ªánh</th>
                    <th>S·ªë M·∫´u</th>
                    <th>T·ª∑ L·ªá (%)</th>
                </tr>
            </thead>
            <tbody>
"""

# Top 10 classes
label_counts = Counter(y_train)
total_samples = len(y_train)
for label_id, count in label_counts.most_common(10):
    disease_name = label_encoder.inverse_transform([label_id])[0]
    percentage = (count / total_samples) * 100
    html_content += f"""
                <tr>
                    <td>{disease_name}</td>
                    <td>{count}</td>
                    <td>{percentage:.2f}%</td>
                </tr>
"""

html_content += """
            </tbody>
        </table>

        <h2>üíæ T·ªáp ƒê√£ L∆∞u</h2>
        <div class="highlight">
            <strong>‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh c√¥ng:</strong>
            <ul>
                <li><code>data/X_train.npy</code> - Features training (Traditional ML)</li>
                <li><code>data/y_train.npy</code> - Labels training</li>
                <li><code>data/X_test.npy</code> - Features test (Traditional ML)</li>
                <li><code>data/y_test.npy</code> - Labels test</li>
                <li><code>data/X_train_dl.npy</code> - Sequences training (Deep Learning)</li>
                <li><code>data/X_test_dl.npy</code> - Sequences test (Deep Learning)</li>
                <li><code>data/tokenizer.joblib</code> - Tokenizer cho Deep Learning</li>
                <li><code>data/label_encoder.joblib</code> - Label Encoder</li>
                <li><code>data/dl_metadata.joblib</code> - Metadata cho Deep Learning</li>
            </ul>
        </div>

        <h2>üìù T·ªïng K·∫øt</h2>
        <div class="highlight">
            <strong>üéØ ƒê√£ ho√†n th√†nh ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu:</strong><br>
            - X·ª≠ l√Ω <strong>{len(train_data)}</strong> m·∫´u training v√† <strong>{len(test_data)}</strong> m·∫´u test<br>
            - T·∫°o d·ªØ li·ªáu cho <strong>{len(np.unique(y_train))}</strong> lo·∫°i b·ªánh kh√°c nhau<br>
            - Chu·∫©n b·ªã d·ªØ li·ªáu cho c·∫£ m√¥ h√¨nh h·ªçc m√°y truy·ªÅn th·ªëng v√† h·ªçc s√¢u<br>
            - T·ª´ v·ª±ng: <strong>{vocab_size}</strong> t·ª´ cho Deep Learning, <strong>{X_train_ml.shape[1]}</strong> t√≠nh nƒÉng cho Traditional ML<br>
            - S·∫µn s√†ng cho b∆∞·ªõc ti·∫øp theo: L·ª±a ch·ªçn v√† hu·∫•n luy·ªán m√¥ h√¨nh
        </div>

        <div class="footer">
            <p>‚è∞ B√°o c√°o ƒë∆∞·ª£c t·∫°o v√†o: """ + time.strftime("%Y-%m-%d %H:%M:%S") + """</p>
            <p>üß† H·ªá Chuy√™n Gia B·ªánh T·∫≠t ViMedical - B∆∞·ªõc 2: Ti·ªÅn X·ª≠ L√Ω D·ªØ Li·ªáu</p>
        </div>
    </div>
</body>
</html>
"""

# L∆∞u file HTML
with open('reports/Step2_Data_Preprocessing.html', 'w', encoding='utf-8') as f:
    f.write(html_content)

print("‚úÖ ƒê√£ t·∫°o b√°o c√°o HTML: reports/Step2_Data_Preprocessing.html")